---
title: "BSMM-lab-5"
subtitle: "BSMM 8740 Fall 2023"
author: "Maisha Farzana"
date: "06 November 2023"
format: html
editor: visual
self-contained: true
---

::: callout-note
## REMINDER:

Be sure to edit this document (see above) to include your name (and the date)

Before you wrap up the assignment, make sure all documents are updated on your GitHub repo (i.e. save, stage, commit and push).

Remember -- you do **not** have to turn in an \*.html file. I will be pulling your work directly from your repository on the [course github site](https://github.com/BSMM-8740-Fall-2023).
:::

## Setup

Today we will be using the Ames Housing Data.

This is a data set from [De Cock](http://jse.amstat.org/v19n3/decock.pdf) (2011) has 82 fields were recorded for 2,930 properties in Ames Iowa in the US. The version in the `modeldata` package is copied from the `AmesHousing` package but does not include a few quality columns that appear to be outcomes rather than predictors.

```{r}
#| eval: false
dat <- modeldata::ames
```

The data dictionary can be found on the internet:

```{r}
#| eval: false
cat(readr::read_file("http://jse.amstat.org/v19n3/decock/DataDocumentation.txt"))
```

## Exercises

### Exercise 1

Write and execute the code to perform summary EDA on the Ames Housing data using the package `skimr`. Show the results.

```{r}
# Load the required libraries
library(skimr)
library(modeldata)

# Load the Ames Housing data
dat <- modeldata::ames

# Perform summary EDA using skimr
summary_dat <- skim(dat)

# Print the results
summary_dat
```

### Exercise 2

Write and execute code to create training and test datasets. Have the training dataset represent 75% of the total data. Name the training dataset **ames_train** and the test dataset **ames_test**

```{r}
library(rsample)

# Set the random seed for reproducibility
set.seed(8740)

# Split the data into training and test datasets
data_split <- initial_split(dat, prop = 0.75)

# Create ames_train and ames_test datasets
ames_train <- training(data_split)
ames_test <- testing(data_split)
```

### Exercise 3

Create a recipe based on the formula **Sale_Price \~ Longitude + Latitude + Lot_Area + Neighborhood + Year_Sold** and with the pre-processing steps specified in the description. Show the output of `broom::tidy()` with your recipes as the argument.

```{r}
library(recipes)
library(broom)

# Create the recipe
norm_recipe <- recipe(Sale_Price ~ Longitude + Latitude + Lot_Area + Neighborhood + Year_Sold, data = dat) %>%
  # Step 1: Transform the outcome variable Sale_Price to log(Sale_Price)
  step_log(Sale_Price) %>%
  # Step 2: Center and scale all numeric predictors
  step_center(all_numeric()) %>%
  step_scale(all_numeric()) %>%
  # Step 3: Transform the categorical variable Neighborhood to pool infrequent values
  step_other(Neighborhood, threshold = 0.01) %>%
  # Step 4: Create dummy variables for all nominal predictors
  step_dummy(all_nominal()) %>%
  # Step 5: Prepare the recipe
  prep()

# Use broom::tidy() to examine the recipe
tidy(norm_recipe)
```

### Exercise 4

Create three regression models using the `parsnip::` package and assign each model to its own variable

-   a base regression model using `lm`
-   a regression model using `glmnet`; set the model parameters `penalty` and `mixture` for tuning
-   a tree model using the `ranger` engine; set the model parameters `min_n` and `trees` for tuning

Evaluate (print) each model variable to show the type of model, the method of fitting and the tuning arguments, if any.

```{r}
library(parsnip)

# Base Linear Regression Model
lm_mod_base <- 
  linear_reg() %>% 
  set_engine("lm")

# GLMNET Model with Tuning Parameters
lm_mod_glmnet <- 
  linear_reg(penalty = tune(), mixture = tune()) %>% 
  set_engine("glmnet")

# Random Forest Model with Tuning Parameters
lm_mod_rforest <- 
  rand_forest(min_n = tune(), trees = tune()) %>% 
  set_engine("ranger")

# Print model details
print(lm_mod_base)
print(lm_mod_glmnet)
print(lm_mod_rforest)
```

### Exercise 5

Use `parsnip::translate()` on each model to see the model template for each method of fitting.

```{r}
library(parsnip)

# Create a random forest model specification
rforest_spec <- rand_forest()

# Use parsnip::translate() for the linear regression and glmnet models
lm_template <- translate(lm_mod_base)
glmnet_template <- translate(lm_mod_glmnet)

# For the random forest model, manually specify the template
rforest_template <- "rand_forest()"

# Print the model templates
print(lm_template)
print(glmnet_template)
cat("Random Forest Model Template:\n")
cat(rforest_template, "\n")
```

### Exercise 6

Create bootstrap samples for the training dataset. You can leave the parameters set to their defaults.

```{r}
library(rsample)

# Create bootstrap samples for the training dataset
bootstraps <- bootstraps(ames_train)

# View the bootstrap samples
bootstraps
```

### Exercise 7

Create workflows with `workflowsets::workflow_set` using your recipe and models. Show the resulting datastructure, noting the number of columns, and then use `tidyr::` to unnest the *info* column and show its contents.

```{r}

library(tidymodels)

# Define the recipe with the specified formula
norm_recipe <- 
  recipe(Sale_Price ~ Longitude + Latitude + Lot_Area + Neighborhood + Year_Sold, data = ames_train) %>%
  step_log(Sale_Price) %>%  # Log-transform the outcome variable
  step_center(all_numeric()) %>%
  step_scale(all_numeric()) %>%
  step_other(Neighborhood, threshold = 0.01, other = "Other") %>%  # Pool infrequent values in Neighborhood
  step_dummy(all_nominal())  # Create dummy variables for nominal predictors

# Create parsnip models
lm_mod_base <- 
  linear_reg() %>%
  set_engine("lm")

lm_mod_glmnet <- 
  linear_reg(penalty = tune(), mixture = tune()) %>%
  set_engine("glmnet")

lm_mod_rforest <- 
  rand_forest(min_n = tune(), trees = tune()) %>%
  set_engine("ranger")

# Set the mode for the "base" model
lm_mod_base <- set_mode(lm_mod_base, "regression")

# Create a workflow set
all_workflows <- 
  workflowsets::workflow_set(
    preproc = list(base = norm_recipe),
    models = list(base = lm_mod_base, glmnet = lm_mod_glmnet, forest = lm_mod_rforest)
  )
# View the structure of the workflow set
str(all_workflows)
```

### Exercise 8

Use `workflowsets::workflow_map` to map the default function (`tune::tune_grid()` - look at the help for `workflowsets::workflow_map` ) across the workflows in the workflowset you just created and update the variable `all_workflows` with the result.

The updated variable `all_workflows` contains a nested column named **result**, and each cell of the column **result** is a tibble containing a nested column named **.metrics**. Write code to

1.  un-nest the metrics in the column .metrics
2.  filter out the rows for the metric rsq
3.  group by wflow_id, order the .estimate column from highest to lowest, and pick out the first row of each group.

```{r}
all_workflows <- all_workflows %>% 
  workflowsets::workflow_map(
    verbose = TRUE,             # Enable logging
    resamples = train_resamples,  # A parameter passed to tune::tune_grid()
    grid = 5                      # A parameter passed to tune::tune_grid()
  )

```

```{r}
result_df <- all_workflows %>%
  dplyr::select(wflow_id, result) %>%  # Select the wflow_id and result columns
  tidyr::unnest(result) %>%           # Unnest the result column
  tidyr::unnest(.metrics) %>%         # Unnest the .metrics column
  dplyr::filter(.metric != 'rsq') %>%  # Filter out rows where .metric is 'rsq'
  dplyr::group_by(wflow_id) %>%       # Group by wflow_id
  dplyr::arrange(desc(.estimate)) %>% # Arrange in descending order of .estimate
  dplyr::slice(1)                    # Pick the first row of each group

# Display the resulting data frame
result_df

```

### Exercise 9

Run the code provided and compare to your results from exercise 8.

```{r}

workflowsets::rank_results(all_workflows, rank_metric = "rsq", select_best = TRUE)
```

### Exercise 10

Select the best model per the **rsq** metric using its id.

What is the ratio of the OOB prediction errors (MSE): test/train?

```{r}
best_model_workflow <- 
  all_workflows %>% 
  workflowsets::extract_workflow("__")
```

```{r}
best_model_workflow <- 
  best_model_workflow %>% 
  tune::finalize_workflow(
    tibble::tibble(param_name = param_value) 
  )

```

```{r}
training_fit <- best_model_workflow %>% 
  fit(data = ames_train)

testing_fit <- best_model_workflow %>% 
  fit(data = ames_test)
```
